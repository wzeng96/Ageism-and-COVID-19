{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk.data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.util import bigrams \n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# can reference to this website if interested: \n",
    "# https://medium.com/@sandeep.panchal545/sentiment-analysis-with-vader-label-the-unlabeled-data-8dd785225166\n",
    "\n",
    "# You might need to install some of the packages, let me know if you need help :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "df = pd.read_csv(\"./Data/mar-apr_All(without COVID-19).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>media</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBTQ community may be 'particularly vulnerabl...</td>\n",
       "      <td>Hide highlightingAbstractTranslateUndo Transla...</td>\n",
       "      <td>USA Today (Online)</td>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meghan McCain announces she's pregnant, self-i...</td>\n",
       "      <td>Hide highlightingAbstractTranslateUndo Transla...</td>\n",
       "      <td>USA Today (Online)</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports Without Live Sports: [Correction]</td>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who gets a shot at life if hospitals run short...</td>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>The Washington Post</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Survivors Fume as China Insists on Quiet Buria...</td>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LGBTQ community may be 'particularly vulnerabl...   \n",
       "1  Meghan McCain announces she's pregnant, self-i...   \n",
       "2           Sports Without Live Sports: [Correction]   \n",
       "3  Who gets a shot at life if hospitals run short...   \n",
       "4  Survivors Fume as China Insists on Quiet Buria...   \n",
       "\n",
       "                                                text                media  \\\n",
       "0  Hide highlightingAbstractTranslateUndo Transla...   USA Today (Online)   \n",
       "1  Hide highlightingAbstractTranslateUndo Transla...   USA Today (Online)   \n",
       "2  Hide highlightingFull TextTranslateUndo Transl...       New York Times   \n",
       "3  Hide highlightingFull TextTranslateUndo Transl...  The Washington Post   \n",
       "4  Hide highlightingFull TextTranslateUndo Transl...       New York Times   \n",
       "\n",
       "   word_count  \n",
       "0        1336  \n",
       "1         316  \n",
       "2         847  \n",
       "3        2186  \n",
       "4        1608  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Hide highlightingAbstractTranslateUndo Transla...\n",
       "1     Hide highlightingAbstractTranslateUndo Transla...\n",
       "2     Hide highlightingFull TextTranslateUndo Transl...\n",
       "3     Hide highlightingFull TextTranslateUndo Transl...\n",
       "4     Hide highlightingFull TextTranslateUndo Transl...\n",
       "5     Hide highlightingFull TextTranslateUndo Transl...\n",
       "6     Hide highlightingFull TextTranslateUndo Transl...\n",
       "7     Hide highlightingFull TextTurn on search term ...\n",
       "8     Hide highlightingAbstractTranslateUndo Transla...\n",
       "9     Hide highlightingFull TextTranslateUndo Transl...\n",
       "10    Hide highlightingFull TextTranslateUndo Transl...\n",
       "11    Hide highlightingFull TextTranslateUndo Transl...\n",
       "12    Hide highlightingFull TextTranslateUndo Transl...\n",
       "13    Hide highlightingFull TextTranslateUndo Transl...\n",
       "14    Hide highlightingFull TextTranslateUndo Transl...\n",
       "15    Hide highlightingFull TextTranslateUndo Transl...\n",
       "16    Hide highlightingAbstractTranslateUndo Transla...\n",
       "17    Hide highlightingAbstractTranslateUndo Transla...\n",
       "18    Hide highlightingFull TextTranslateUndo Transl...\n",
       "19    Hide highlightingAbstractTranslateUndo Transla...\n",
       "20    Hide highlightingAbstractTranslateUndo Transla...\n",
       "21    Hide highlightingFull TextTranslateUndo Transl...\n",
       "22    Hide highlightingAbstractTranslateUndo Transla...\n",
       "23    Hide highlightingFull TextTranslateUndo Transl...\n",
       "24    Hide highlightingFull TextTranslateUndo Transl...\n",
       "25    Hide highlightingFull TextTranslateUndo Transl...\n",
       "26    Hide highlightingFull TextTranslateUndo Transl...\n",
       "27    Hide highlightingFull TextTurn on search term ...\n",
       "28    Hide highlightingFull TextTranslateUndo Transl...\n",
       "29    Hide highlightingFull TextTranslateUndo Transl...\n",
       "30    Hide highlightingFull TextTranslateUndo Transl...\n",
       "31    Hide highlightingFull TextTranslateUndo Transl...\n",
       "32    Hide highlightingFull TextTranslateUndo Transl...\n",
       "33    Hide highlightingAbstractTranslateUndo Transla...\n",
       "34    Hide highlightingFull TextTranslateUndo Transl...\n",
       "35    Hide highlightingAbstractTranslateUndo Transla...\n",
       "36    Hide highlightingFull TextTranslateUndo Transl...\n",
       "37    Hide highlightingFull TextTranslateUndo Transl...\n",
       "38    Hide highlightingAbstractTranslateUndo Transla...\n",
       "39    Hide highlightingFull TextTranslateUndo Transl...\n",
       "40    Hide highlightingFull TextTranslateUndo Transl...\n",
       "41    Hide highlightingAbstractTranslateUndo Transla...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract text\n",
    "df_text = df.iloc[:,1]\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Sentiment Analysis for each candidates\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each token as positive, negative or neutral, and generate a score\n",
    "\n",
    "df_table = []\n",
    "for i in df['text']:\n",
    "    df_scores = {}\n",
    "    df_scores['sia_positive'] = sia.polarity_scores(i)['pos']*100\n",
    "    df_scores['sia_negative'] = sia.polarity_scores(i)['neg']*100\n",
    "    df_scores['sia_neutral'] = sia.polarity_scores(i)['neu']*100\n",
    "    df_scores['sia_compound'] = sia.polarity_scores(i)['compound']\n",
    "    \n",
    "    df_table.append(df_scores)\n",
    "    \n",
    "#print(sia_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sia_positive  sia_negative  sia_neutral  sia_compound\n",
      "0            9.0           7.3         83.7        0.9921\n",
      "1            9.8           2.6         87.7        0.9957\n",
      "2           15.6           4.9         79.6        0.9991\n",
      "3            8.9           7.6         83.6        0.9834\n",
      "4            9.3          10.7         79.9       -0.9638\n",
      "5            8.3           7.8         83.9        0.8324\n",
      "6            6.6           6.1         87.3        0.8890\n",
      "7            7.7          11.6         80.7       -0.9921\n",
      "8            7.4           6.3         86.3        0.9978\n",
      "9            7.5          12.7         79.7       -0.9971\n",
      "10           8.1           2.9         89.0        0.9979\n",
      "11           8.1          10.6         81.3       -0.9992\n",
      "12           9.3          11.2         79.4       -0.9940\n",
      "13           5.9           5.8         88.3        0.5890\n",
      "14           7.0           5.7         87.3        0.9867\n",
      "15          10.0           9.1         80.9        0.9751\n",
      "16          14.6           8.1         77.3        0.9988\n",
      "17           8.7          10.4         80.9       -0.9759\n",
      "18           7.9           9.4         82.7       -0.9928\n",
      "19           9.0           6.5         84.6        0.9973\n",
      "20           7.0           7.1         85.9       -0.6944\n",
      "21           8.7           5.4         85.9        0.9945\n",
      "22           8.7           4.8         86.5        0.9961\n",
      "23           7.6           5.5         86.9        0.9905\n",
      "24           5.9           4.3         89.8        0.9587\n",
      "25           6.3           5.4         88.3        0.9755\n",
      "26          10.6           1.3         88.1        0.9992\n",
      "27           6.6           7.6         85.8       -0.8576\n",
      "28           5.8           7.4         86.7       -0.9992\n",
      "29          13.8           7.5         78.7        0.9994\n",
      "30          12.5          10.2         77.3        0.9975\n",
      "31          12.5          10.4         77.1        0.9969\n",
      "32           8.5           3.9         87.6        0.9987\n",
      "33           7.0           7.2         85.8       -0.9931\n",
      "34           5.5           5.7         88.9       -0.5572\n",
      "35          11.5           7.3         81.2        0.9972\n",
      "36          10.1           3.8         86.1        0.9982\n",
      "37           6.7           4.5         88.7        0.9917\n",
      "38           8.8           5.1         86.1        0.9998\n",
      "39           8.6           3.5         87.8        0.9988\n",
      "40           7.5           7.3         85.2        0.6339\n",
      "41           7.3           6.4         86.3        0.9935\n"
     ]
    }
   ],
   "source": [
    "# See the results\n",
    "df_table = pd.DataFrame(df_table)\n",
    "#df_table=df_table.sort_values(by='sia_compound' , ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sia_positive</th>\n",
       "      <th>sia_negative</th>\n",
       "      <th>sia_neutral</th>\n",
       "      <th>sia_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mar - Apr 2020</th>\n",
       "      <td>8.719048</td>\n",
       "      <td>6.878571</td>\n",
       "      <td>84.4</td>\n",
       "      <td>0.422333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sia_positive  sia_negative  sia_neutral  sia_compound\n",
       "Mar - Apr 2020      8.719048      6.878571         84.4      0.422333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what kinds of sentiment appear more\n",
    "df_mean = df_table.mean()\n",
    "df_mean = df_mean.to_frame().transpose()\n",
    "df_mean = df_mean.rename(index={0:'Mar - Apr 2020'})\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think there's some problem with the result. We still need to do some research on this, I'll start googling this issue.\n",
    "1. The mean method might be wrong. Not sure if we can use mean() to evaluate the results.\n",
    "2. General rules for compound values:\n",
    "    >x >= 0.05 positive | \n",
    "    -0.05 < x < 0.05 neutral | \n",
    "    x <= -0.05 negative\n",
    "    >\n",
    "  We can see that our compound values' polarities are super high, which might not be common. \n",
    "3. I've googled around, and saw that most of the values for pos, neg and neu are between 0 and 1. To be honest, I don't know why we have such high values for each article\n",
    "    >We might need to remove the noises and break up the sentences,and then apply the analyzer.\n",
    "4. We could also look at the results base on different medias.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step can be generated after we achieve all three periods of time.\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     'sia_positve': [8.795111, 9.393333, 9.904222],\n",
    "#     'sia_negative': [6.300889, 5.545556, 5.417778],\n",
    "#     'sia_neutral': [84.904889, 85.062222, 84.674000]\n",
    "# }, index=['Nov - Dec 2019', 'Jan - Feb 2020', 'Mar - Apr 2020'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step can also be generated after we achieve the full results.\n",
    "\n",
    "# N = 3\n",
    "# ind = np.arange(N)  # the x locations for the groups\n",
    "# width = 0.27       # the width of the bars\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# yvals = [8.795111, 6.300889,84.904889]\n",
    "# rects1 = ax.bar(ind, yvals, width, color='r')\n",
    "# zvals = [9.393333, 5.545556, 85.062222]\n",
    "# rects2 = ax.bar(ind+width, zvals, width, color='g')\n",
    "# kvals = [9.904222, 5.417778, 84.674000]\n",
    "# rects3 = ax.bar(ind+width*2, kvals, width, color='b')\n",
    "\n",
    "\n",
    "# ax.set_ylabel('Scores')\n",
    "# ax.set_xticks(ind+width)\n",
    "# ax.set_xticklabels( ('SIA_Positive', 'SIA_Negative', 'SIA_Neutral') )\n",
    "# ax.legend((rects1[0], rects2[0], rects3[0]), ('Trump', 'Biden', 'Sanders'), loc = 'best' )\n",
    "\n",
    "\n",
    "# def autolabel(rects):\n",
    "#     for rect in rects:\n",
    "#         h = rect.get_height()\n",
    "#         ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n",
    "#                 ha='center', va='bottom')\n",
    "\n",
    "# autolabel(rects1)\n",
    "# autolabel(rects2)\n",
    "# autolabel(rects3)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
